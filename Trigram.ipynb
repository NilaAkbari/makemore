{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    with open('names.txt', 'r') as f:\n",
    "        names = f.read().splitlines()\n",
    "    return names\n",
    "    \n",
    "names = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating \"stoi\" and \"itos\"\n",
    "chars = sorted(list(set(''.join(names))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = [], []\n",
    "\n",
    "for n in names:\n",
    "    chs = ['.', '.'] + list(n) + ['.','.']\n",
    "    for chs1, chs2, chs3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[chs1]\n",
    "        ix2 = stoi[chs2]\n",
    "        ix3 = stoi[chs3]\n",
    "        xs.append((ix1, ix2))\n",
    "        ys.append(ix3)\n",
    "    \n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one-hot encoded of xs\n",
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "xenc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([260179, 2, 27])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.cat([xenc[0][0], xenc[0][1]])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc_cat = xenc.view(-1, 2*27)\n",
    "xenc_cat[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing W\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((2*27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260179"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = xenc.shape[0]\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  2.0649526119232178\n",
      "loss:  2.0632147789001465\n",
      "loss:  2.0617709159851074\n",
      "loss:  2.0605547428131104\n",
      "loss:  2.0595171451568604\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "\n",
    "    logits = xenc_cat @ W #equivalent to count's logarithm\n",
    "    counts = logits.exp()\n",
    "    probs = counts/counts.sum(1, keepdim=True)\n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "    if i % 20 == 0:\n",
    "        print(\"loss: \", loss.item())\n",
    "\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    #update\n",
    "    W.data += -40 * W.grad\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-10.5057,   2.8836,   0.5967,  ...,  -0.9788,   1.3044,   1.1338],\n",
      "        [  1.5782,   0.3635,  -0.2223,  ...,  -1.5943,  -0.1607,  -0.2388],\n",
      "        [  0.7839,   1.3579,  -0.0716,  ...,  -0.4852,   0.6638,  -1.2331],\n",
      "        ...,\n",
      "        [  0.2618,   0.4977,  -0.4188,  ...,   0.5696,   0.2397,   0.0908],\n",
      "        [  1.3077,   1.9957,  -0.6259,  ...,  -0.9937,  -1.6430,   0.1324],\n",
      "        [  0.0848,   2.2522,  -0.2436,  ...,  -0.3140,   1.5923,   0.2865]],\n",
      "       requires_grad=True) <built-in method type of Tensor object at 0x0000023BDC1482D0>\n"
     ]
    }
   ],
   "source": [
    "print(W, W.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([54, 27])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juwide\n",
      "janasad\n",
      "pariay\n",
      "ainn\n",
      "koi\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "    ix1 = 0 \n",
    "    ix2 = 0 #because we begin our words from .. which is index 0\n",
    "    out = []\n",
    "    while True:\n",
    "        xenc = F.one_hot(torch.tensor([ix1, ix2]), num_classes=27).float().reshape(-1)\n",
    "        logits = xenc @ W\n",
    "        p = logits.exp()/(logits.exp().sum(-1, keepdim=True))\n",
    "        ix1 = ix2\n",
    "        ix2 = torch.multinomial(p, num_samples=1, replacement=True, generator=g ).item()\n",
    "        if ix2 == 0:\n",
    "            break\n",
    "        out.append(itos[ix2])\n",
    "\n",
    "    print(''.join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
